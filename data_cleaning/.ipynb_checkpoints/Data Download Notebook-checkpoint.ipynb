{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning & standardizing functions (from exploratory data analysis notebook) - to be used on each data set\n",
    "# downloaded from the Citi bike website\n",
    "def getDist(row):\n",
    "    start = [row[\"start station latitude\"], row[\"start station longitude\"]]\n",
    "    end = [row[\"end station latitude\"], row[\"end station longitude\"]]\n",
    "    sec = row[\"tripduration\"]\n",
    "    total_coord_dist = distance.cdist([start], [end], 'cityblock')\n",
    "    return (total_coord_dist*69*3600/(sec))[0][0]\n",
    "\n",
    "def getRiderAge(df):\n",
    "    df[\"rider_age\"] = df[\"birth year\"].apply(lambda x: datetime.datetime.now().year - x)\n",
    "    #remove \"outlier\" values over ~80 years old\n",
    "    df = df.loc[df[\"rider_age\"] <= 80]\n",
    "    return df\n",
    "    \n",
    "def getAvgSpeed(df):\n",
    "    df[\"avg_speed\"] = df.apply(lambda row: getDist(row), axis=1)\n",
    "    return df\n",
    "    \n",
    "#start to make a cleaning/organizing function for new data frame imports\n",
    "def addCols(df):\n",
    "    df = getRiderAge(df)\n",
    "    df = getAvgSpeed(df)\n",
    "    #drop duplicates in case there are any\n",
    "    df = df.drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://s3.amazonaws.com/tripdata/201801-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201804-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201805-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201806-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201807-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201808-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201809-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201810-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201811-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201812-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201901-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201902-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201903-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201904-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201905-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201906-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201907-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201908-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201909-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201910-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201911-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/201912-citibike-tripdata.csv.zip',\n",
       " 'https://s3.amazonaws.com/tripdata/202001-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#uses the \"requests\" python library and a custom, formatted url string \n",
    "#to get a range of csvs downloaded, with the \"start\" and \"end\" parameters in the \n",
    "#form of [month, year], with months numbered 1 through 12 and year being 2017 or later\n",
    "def getCSVZips(start, end):\n",
    "    #validate inputs here later - ensuring that the \"end\" argument is after \"start\"\n",
    "    \n",
    "    #array to return with url strings\n",
    "    output = []\n",
    "    for year in range(start[1], end[1]+1):\n",
    "        if(start[1]==year):\n",
    "            start_month = start[0]\n",
    "        else:\n",
    "            start_month = 1\n",
    "        \n",
    "        for month in range(start_month, 13):\n",
    "            curr_url = \"https://s3.amazonaws.com/tripdata/{}{:0>2d}-citibike-tripdata.csv.zip\".format(year, month)\n",
    "            output.append(curr_url)\n",
    "            if(end[0]==month and end[1]==year):\n",
    "                return output\n",
    "\n",
    "getCSVZips([1, 2018], [1, 2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get the data for the past 3 years to look for seasonal trends \n",
    "url_list = getCSVZips([8, 2017], [8, 2020])\n",
    "\n",
    "response = requests.get(url_list[0], allow_redirects=True)\n",
    "open(\"../raw_data/\" + url_list[0].split(\"/\")[-1], 'wb').write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seemed to work, get last year of data\n",
    "url_last_year = getCSVZips([8, 2017], [8, 2019])\n",
    "\n",
    "for url in url_last_year:\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    open(\"../raw_data/\" + url.split(\"/\")[-1], 'wb').write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['201708-citibike-tripdata.csv.zip',\n",
       " '201709-citibike-tripdata.csv.zip',\n",
       " '201710-citibike-tripdata.csv.zip',\n",
       " '201711-citibike-tripdata.csv.zip',\n",
       " '201712-citibike-tripdata.csv.zip',\n",
       " '201801-citibike-tripdata.csv.zip',\n",
       " '201802-citibike-tripdata.csv.zip',\n",
       " '201803-citibike-tripdata.csv.zip',\n",
       " '201804-citibike-tripdata.csv.zip',\n",
       " '201805-citibike-tripdata.csv.zip',\n",
       " '201806-citibike-tripdata.csv.zip',\n",
       " '201807-citibike-tripdata.csv.zip',\n",
       " '201808-citibike-tripdata.csv.zip',\n",
       " '201809-citibike-tripdata.csv.zip',\n",
       " '201810-citibike-tripdata.csv.zip',\n",
       " '201811-citibike-tripdata.csv.zip',\n",
       " '201812-citibike-tripdata.csv.zip',\n",
       " '201901-citibike-tripdata.csv.zip',\n",
       " '201902-citibike-tripdata.csv.zip',\n",
       " '201903-citibike-tripdata.csv.zip',\n",
       " '201904-citibike-tripdata.csv.zip',\n",
       " '201905-citibike-tripdata.csv.zip',\n",
       " '201906-citibike-tripdata.csv.zip',\n",
       " '201907-citibike-tripdata.csv.zip',\n",
       " '201908-citibike-tripdata.csv.zip',\n",
       " '201909-citibike-tripdata.csv.zip',\n",
       " '201910-citibike-tripdata.csv.zip',\n",
       " '201911-citibike-tripdata.csv.zip',\n",
       " '201912-citibike-tripdata.csv.zip',\n",
       " '202001-citibike-tripdata.csv.zip',\n",
       " '202002-citibike-tripdata.csv.zip',\n",
       " '202003-citibike-tripdata.csv.zip',\n",
       " '202004-citibike-tripdata.csv.zip',\n",
       " '202005-citibike-tripdata.csv.zip',\n",
       " '202006-citibike-tripdata.csv.zip',\n",
       " '202007-citibike-tripdata.csv.zip',\n",
       " '202008-citibike-tripdata.csv.zip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now get file names for all files in the three-year period \n",
    "file_list = list(map(lambda x: x.split(\"/\")[-1], getCSVZips([8, 2017], [8, 2020])))\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over list and make a .csv output file for each \"year\" by time duration - 12 files combined\n",
    "#still a little rough with the \"start month\" and \"end month\" part of the function\n",
    "def combineCSVs(file_list, start_year, end_year, start_month, num_months=12):\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for i in range(num_months):\n",
    "            curr_file = file_list.pop(0)\n",
    "            curr_df = pd.read_csv(\"../raw_data/\"+curr_file)\n",
    "            curr_df = addCols(curr_df)\n",
    "            print(\"{} done!\".format(curr_file[0:6]))\n",
    "            if(i==0): \n",
    "                full_df = curr_df\n",
    "            else:\n",
    "                full_df = full_df.append(curr_df, ignore_index=True)\n",
    "        full_df.to_csv(\"../raw_data/year_combined/{:0>2d}-{}__{:0>2d}-{}.csv\".format(start_month, year, num_months+start_month-1, year), index=False)\n",
    "        print(\"{} csv output\".format(year))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Select Summer, Winter files\n",
    "* data for last year had +18M rows, Tableau Public only allows 15M rows\n",
    "* original project scope too broad/extensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201906 done!\n",
      "201907 done!\n",
      "201908 done!\n",
      "201909 done!\n",
      "2019 csv output\n"
     ]
    }
   ],
   "source": [
    "summer_2019_files = list(map(lambda x: x.split(\"/\")[-1], getCSVZips([6, 2019], [9, 2019])))\n",
    "combineCSVs(summer_2019_files, 2019, 2019, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201812 done!\n",
      "201901 done!\n",
      "201902 done!\n",
      "201903 done!\n",
      "2019 csv output\n"
     ]
    }
   ],
   "source": [
    "winter_2019_files = list(map(lambda x: x.split(\"/\")[-1], getCSVZips([12, 2018], [3, 2019])))\n",
    "combineCSVs(winter_2019_files, 2019, 2019, 12, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
